<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Model Transcription · InfiniteOpt.jl</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-178297470-1"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-178297470-1', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/extra_styles.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.png" alt="InfiniteOpt.jl logo"/><img class="docs-dark-only" src="../../assets/logo-dark.png" alt="InfiniteOpt.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">InfiniteOpt.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../install/">Installation</a></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../tutorials/quick_start/">Quick Start</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><input class="collapse-toggle" id="menuitem-4-1" type="checkbox"/><label class="tocitem" for="menuitem-4-1"><span class="docs-label">Optimal Control</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../examples/Optimal Control/consumption_savings/">Consumption Savings Problem</a></li><li><a class="tocitem" href="../../examples/Optimal Control/hovercraft/">Hovercraft Path Planning</a></li><li><a class="tocitem" href="../../examples/Optimal Control/pandemic_control/">Pandemic Control</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-2" type="checkbox"/><label class="tocitem" for="menuitem-4-2"><span class="docs-label">Stochastic Optimization</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../examples/Stochastic Optimization/farmer/">Two-Stage Stochastic Program</a></li><li><a class="tocitem" href="../../examples/Stochastic Optimization/flexible_design/">Power Network Flexibility Design</a></li></ul></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox" checked/><label class="tocitem" for="menuitem-5"><span class="docs-label">User Guide</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../model/">Infinite Models</a></li><li><a class="tocitem" href="../domains/">Infinite Domains</a></li><li><a class="tocitem" href="../parameter/">Infinite Parameters</a></li><li><a class="tocitem" href="../finite_parameter/">Finite Parameters</a></li><li><a class="tocitem" href="../variable/">Variables</a></li><li><a class="tocitem" href="../derivative/">Derivatives</a></li><li><a class="tocitem" href="../expression/">Expressions</a></li><li><a class="tocitem" href="../measure/">Measures</a></li><li><a class="tocitem" href="../objective/">Objectives</a></li><li><a class="tocitem" href="../constraint/">Constraints</a></li><li class="is-active"><a class="tocitem" href>Model Transcription</a><ul class="internal"><li><a class="tocitem" href="#Overview"><span>Overview</span></a></li><li><a class="tocitem" href="#Basic-Usage"><span>Basic Usage</span></a></li><li><a class="tocitem" href="#Transcription-Theory"><span>Transcription Theory</span></a></li><li><a class="tocitem" href="#TranscriptionOpt"><span>TranscriptionOpt</span></a></li></ul></li><li><a class="tocitem" href="../optimize/">Optimization</a></li><li><a class="tocitem" href="../result/">Results</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">API Manual</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../manual/model/">Infinite Models</a></li><li><a class="tocitem" href="../../manual/domains/">Infinite Domains</a></li><li><a class="tocitem" href="../../manual/parameter/">Infinite Parameters</a></li><li><a class="tocitem" href="../../manual/finite_parameter/">Finite Parameters</a></li><li><a class="tocitem" href="../../manual/variable/">Variables</a></li><li><a class="tocitem" href="../../manual/derivative/">Derivatives</a></li><li><a class="tocitem" href="../../manual/expression/">Expressions</a></li><li><a class="tocitem" href="../../manual/measure/">Measures</a></li><li><a class="tocitem" href="../../manual/objective/">Objectives</a></li><li><a class="tocitem" href="../../manual/constraint/">Constraints</a></li><li><a class="tocitem" href="../../manual/transcribe/">Model Transcription</a></li><li><a class="tocitem" href="../../manual/optimize/">Optimization</a></li><li><a class="tocitem" href="../../manual/result/">Results</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-7" type="checkbox"/><label class="tocitem" for="menuitem-7"><span class="docs-label">Development</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../develop/extensions/">Extensions</a></li><li><a class="tocitem" href="../../develop/start_guide/">Getting Started</a></li><li><a class="tocitem" href="../../develop/style/">Style Guide</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">User Guide</a></li><li class="is-active"><a href>Model Transcription</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Model Transcription</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/pulsipher/InfiniteOpt.jl/blob/master/docs/src/guide/transcribe.md#L" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="transcription_docs"><a class="docs-heading-anchor" href="#transcription_docs">Model Transcription</a><a id="transcription_docs-1"></a><a class="docs-heading-anchor-permalink" href="#transcription_docs" title="Permalink"></a></h1><p>A guide for transcribing infinite models in <code>InfiniteOpt</code>. See the respective  <a href="../../manual/transcribe/#transcription_manual">technical manual</a> for more details.</p><h2 id="Overview"><a class="docs-heading-anchor" href="#Overview">Overview</a><a id="Overview-1"></a><a class="docs-heading-anchor-permalink" href="#Overview" title="Permalink"></a></h2><p>All infinite models need to be reformulated in such a way that they can be solved  using traditional optimization methods. Typically, this involves discretization  of the infinite domain via particular parameter support points. By default,  <code>InfiniteOpt</code> employs this methodology via the use of transcription models (which  comprise the <code>optimizer_model</code> as discussed in the  <a href="../model/#infinite_model_docs">Infinite Models</a> section). <code>InfiniteOpt</code> is built  modularly to readily accept other user defined techniques and this is discussed  in further detail on the <a href="../../develop/extensions/#Extensions">Extensions</a> page. This page will detail  transcription models based in <code>InfiniteOpt.TranscriptionOpt</code> which provide the  default transcription (reformulation) capabilities of <code>InfiniteOpt</code>.</p><h2 id="Basic-Usage"><a class="docs-heading-anchor" href="#Basic-Usage">Basic Usage</a><a id="Basic-Usage-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-Usage" title="Permalink"></a></h2><p>Most users will not need to employ the capabilities of <code>TranscriptionOpt</code> directly  since they are employed implicitly with the call of  <a href="../../manual/optimize/#JuMP.optimize!-Tuple{InfiniteModel}"><code>optimize!</code></a> on an infinite model. This  occurs since <code>TranscriptionModel</code>s are the default optimizer model type that is  employed. </p><p>However, some users may wish to use <code>TranscriptionOpt</code> to extract a fully  discretized/transcribed version of an infinite model that is conveniently output  as a typical <code>JuMP</code> model and can then be treated as such. This is principally  accomplished via <a href="../../manual/optimize/#InfiniteOpt.build_optimizer_model!"><code>build_optimizer_model!</code></a>. To illustrate how this is done,  let&#39;s first define a basic infinite model with a simple support structure for the  sake of example:</p><pre><code class="language-julia-repl">julia&gt; using InfiniteOpt

julia&gt; inf_model = InfiniteModel();

julia&gt; @infinite_parameter(inf_model, t in [0, 10], supports = [0, 5, 10])
t

julia&gt; @variable(inf_model, y &gt;= 0, Infinite(t))
y(t)

julia&gt; @variable(inf_model, z, Bin)
z

julia&gt; @objective(inf_model, Min, 2z + support_sum(y, t))
2 z + support_sum{t}[y(t)]

julia&gt; @constraint(inf_model, initial, y(0) == 1)
initial : y(0) = 1.0

julia&gt; @constraint(inf_model, constr, y^2 - z &lt;= 42)
constr : y(t)² - z ≤ 42.0, ∀ t ∈ [0, 10]

julia&gt; print(inf_model)
Min 2 z + support_sum{t}[y(t)]
Subject to
 y(t) ≥ 0.0, ∀ t ∈ [0, 10]
 z binary
 y(0) ≥ 0.0
 initial : y(0) = 1.0
 constr : y(t)² - z ≤ 42.0, ∀ t ∈ [0, 10]</code></pre><p>Now we can make <code>JuMP</code> model containing the transcribed version of <code>inf_model</code>  via <a href="../../manual/optimize/#InfiniteOpt.build_optimizer_model!"><code>build_optimizer_model!</code></a> and then extract it via  <a href="../../manual/optimize/#InfiniteOpt.optimizer_model"><code>optimizer_model</code></a>:</p><pre><code class="language-julia-repl">julia&gt; build_optimizer_model!(inf_model)

julia&gt; trans_model = optimizer_model(inf_model)
A JuMP Model
Minimization problem with:
Variables: 4
Objective function type: AffExpr
`AffExpr`-in-`MathOptInterface.EqualTo{Float64}`: 1 constraint
`QuadExpr`-in-`MathOptInterface.LessThan{Float64}`: 3 constraints
`VariableRef`-in-`MathOptInterface.GreaterThan{Float64}`: 3 constraints
`VariableRef`-in-`MathOptInterface.ZeroOne`: 1 constraint
Model mode: AUTOMATIC
CachingOptimizer state: NO_OPTIMIZER
Solver name: No optimizer attached.

julia&gt; print(trans_model)
Min 2 z + y(support: 1) + y(support: 2) + y(support: 3)
Subject to
 initial(support: 1) : y(support: 1) = 1.0
 constr(support: 1) : y(support: 1)² - z ≤ 42.0
 constr(support: 2) : y(support: 2)² - z ≤ 42.0
 constr(support: 3) : y(support: 3)² - z ≤ 42.0
 y(support: 1) ≥ 0.0
 y(support: 2) ≥ 0.0
 y(support: 3) ≥ 0.0
 z binary</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Previous versions of InfiniteOpt, employed a <code>TranscriptionModel(model::InfiniteModel)</code>  constructor to build transcription models independently of the optimizer model.  This has functionality has been removed in favor of internal optimizer model  based builds for efficiency reasons and to properly manage MOI optimizer  attributes.</p></div></div><p>Thus, we have a transcribed <code>JuMP</code> model. To be precise this is actually a  <code>TranscriptionModel</code> which is a <code>JuMP.Model</code> with some extra data stored in the  <code>ext</code> field that retains the mapping between the transcribed variables/constraints  and their infinite counterparts. Notice, that multiple finite variables  have been introduced to discretize <code>y(t)</code> at supports 1, 2, and 3 which correspond  to 0, 5, and 10 as can be queried by <code>supports</code>:</p><pre><code class="language-julia-repl">julia&gt; supports(y)
3-element Vector{Tuple}:
 (0.0,)
 (5.0,)
 (10.0,)</code></pre><p>Also, notice how the constraints are transcribed in accordance with these supports  except the initial condition which naturally is only invoked for the first support  point. Furthermore, the transcription variable(s) of any variable associated with  the infinite model can be determined via <a href="../../manual/transcribe/#InfiniteOpt.TranscriptionOpt.transcription_variable-Tuple{Model, GeneralVariableRef}"><code>transcription_variable</code></a>:</p><pre><code class="language-julia-repl">julia&gt; transcription_variable(y)
3-element Vector{VariableRef}:
 y(support: 1)
 y(support: 2)
 y(support: 3)

julia&gt; transcription_variable(trans_model, z)
z</code></pre><p>Similarly, the transcription constraints associated with infinite model constraints  can be queried via <a href="../../manual/transcribe/#InfiniteOpt.TranscriptionOpt.transcription_constraint-Tuple{Model, InfOptConstraintRef}"><code>transcription_constraint</code></a> and the associated supports  and infinite parameters can be found via <code>supports</code> and <code>parameter_refs</code>:</p><pre><code class="language-julia-repl">julia&gt; transcription_constraint(initial)
initial(support: 1) : y(support: 1) = 1.0

julia&gt; transcription_constraint(constr)
3-element Vector{ConstraintRef}:
 constr(support: 1) : y(support: 1)² - z ≤ 42.0
 constr(support: 2) : y(support: 2)² - z ≤ 42.0
 constr(support: 3) : y(support: 3)² - z ≤ 42.0

julia&gt; supports(constr)
3-element Vector{Tuple}:
 (0.0,)
 (5.0,)
 (10.0,)

julia&gt; parameter_refs(constr)
(t,)</code></pre><p>Note the parameter reference tuple corresponds to the support tuples. </p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Method that query the transcription surrogates (e.g., <code>transcription_variable</code>)  and the respective supports via <code>supports</code> also accept the keyword argument  <code>label</code> to specify which that transcription objects are desired in accordance  to the support labels that are inherited from and/or are equal to <code>label</code>. By  default, this will return any supports that are public (i.e., will hide anything  solely associated with internal supports). The full query response can always  be obtained via <code>label = All</code>.</p></div></div><p>Now we have a transcribed <code>JuMP</code> model that can be optimized via traditional  <code>JuMP</code> methods whose variables and constraints can be accessed using the methods  mentioned above.</p><h2 id="Transcription-Theory"><a class="docs-heading-anchor" href="#Transcription-Theory">Transcription Theory</a><a id="Transcription-Theory-1"></a><a class="docs-heading-anchor-permalink" href="#Transcription-Theory" title="Permalink"></a></h2><p>A given infinite-dimensional optimization problem is parameterized according to  infinite parameters following our abstraction. In general, most solution strategies  transcribe the problem according to certain finite parameter values (supports) and  thus represent the problem in terms of these supports (e.g., using discrete time  points in dynamic optimization). This methodology can be generalized into the  following steps:</p><ol><li>define supports for each infinite parameter if not already defined,</li><li>add any additional support needed for derivative evaluation,</li><li>expand any measures according to their underlying numerical representation </li></ol><p>using transcribed infinite variables as appropriate,</p><ol><li>replace any remaining infinite variables/derivatives with transcribed  variables supported over each unique combination of the underlying parameter  supports,</li><li>replace any remaining infinite constraints with transcribed ones supported over </li></ol><p>all the unique support combinations stemming from the infinite parameters they     depend on,</p><ol><li>and add on the transcribed versions of the auxiliary derivative evaluation </li></ol><p>equations. </p><p>For example, let&#39;s consider a space-time optimization problem of the form:</p><p class="math-container">\[\begin{aligned}
	&amp;&amp;\min_{y(t), g(t, x)} &amp;&amp;&amp; \int_0^{10} y^2(t) dt \\
	&amp;&amp;\text{s.t.} &amp;&amp;&amp; y(0) = 1 \\
	&amp;&amp;&amp;&amp;&amp; \int_{x \in [-1, 1]^2} \frac{\partial g(t, x)}{\partial t} dx = 42, &amp;&amp; \forall t \in [0, 10] \\
  &amp;&amp;&amp;&amp;&amp; 3g(t, x) + 2y^2(t) \leq 2, &amp;&amp; \forall t \in T, \ x \in [-1, 1]^2. \\
\end{aligned}\]</p><p>Thus, we have an optimization problem whose decision space is infinite with  respect to time <span>$t$</span> and position <span>$x$</span>. Now let&#39;s transcript it following the  above steps. First, we need to specify the infinite parameter supports and for  simplicity let&#39;s choose the following sparse sets:</p><ul><li><span>$t \in \{0, 10\}$</span></li><li><span>$x \in \{[-1, -1]^T, [-1, 1]^T, [1, -1]^T, [1, 1]^T\}$</span>.</li></ul><p>To handle the derivative <span>$\frac{\partial g(t, x)}{\partial t}$</span>, we&#39;ll use    backward finite difference so no additional supports will need to be added.</p><p>Now we expand the two integrals (measures) via a finite approximation using only  the above supports and term coefficients of 1 (note this is not numerically  correct but is done for conciseness in example). Doing this, we obtain the  form:</p><p class="math-container">\[\begin{aligned}
	&amp;&amp;\min_{y(t), g(t, x)} &amp;&amp;&amp; y^2(0) + y^2(10) \\
	&amp;&amp;\text{s.t.} &amp;&amp;&amp; y(0) = 1 \\
  &amp;&amp;&amp;&amp;&amp; g(0, x) = 0 \\
	&amp;&amp;&amp;&amp;&amp; \frac{\partial g(t, [-1, -1])}{\partial t} + \frac{\partial g(t, [-1, 1])}{\partial t} + \frac{\partial g(t, [1, -1])}{\partial t} + \frac{\partial g(t, [1, 1])}{\partial t} = 42, &amp;&amp; \forall t \in [0, 10] \\
  &amp;&amp;&amp;&amp;&amp; 3g(t, x) + 2y^2(t) \leq 2, &amp;&amp; \forall t \in T, \ x \in [-1, 1]^2. \\
\end{aligned}\]</p><p>Notice that the infinite variable <span>$y(t)$</span> in the objective measure has been  replaced with finite transcribed variables <span>$y(0)$</span> and <span>$y(10)$</span>. Also, the  infinite derivative <span>$\frac{\partial g(t, x)}{\partial t}$</span> was replaced with   partially transcribed variables in the second constraint in accordance with the  measure over the positional domain <span>$x$</span>.</p><p>Now we need to transcribe the remaining infinite and semi-infinite variables  with finite variables and duplicate the remaining infinite constraints accordingly.  This means that the second constraint needs to be transcribed over the time domain  and the third constraint needs to be transcribed for each unique combination  of the time and position supports. Applying this transcription yields: </p><p class="math-container">\[\begin{aligned}
	&amp;&amp;\min_{y(t), g(t, x)} &amp;&amp;&amp; y^2(0) + y^2(10) \\
	&amp;&amp;\text{s.t.} &amp;&amp;&amp; y(0) = 1 \\
  &amp;&amp;&amp;&amp;&amp; g(0, [-1, -1]) = 0 \\
  &amp;&amp;&amp;&amp;&amp; g(0, [-1, 1]) = 0 \\
  &amp;&amp;&amp;&amp;&amp; g(0, [1, -1]) = 0 \\
  &amp;&amp;&amp;&amp;&amp; g(0, [1, 1]) = 0 \\
	&amp;&amp;&amp;&amp;&amp; \frac{\partial g(0, [-1, -1])}{\partial t} + \frac{\partial g(0, [-1, 1])}{\partial t} + \frac{\partial g(0, [1, -1])}{\partial t} + \frac{\partial g(0, [1, 1])}{\partial t} = 42\\
  &amp;&amp;&amp;&amp;&amp; \frac{\partial g(10, [-1, -1])}{\partial t} + \frac{\partial g(10, [-1, 1])}{\partial t} + \frac{\partial g(10, [1, -1])}{\partial t} + \frac{\partial g(10, [1, 1])}{\partial t} = 42\\
  &amp;&amp;&amp;&amp;&amp; 3g(0, [-1, -1]) + 2y^2(0) \leq 2 \\
  &amp;&amp;&amp;&amp;&amp; 3g(0, [-1, 1]) + 2y^2(0) \leq 2 \\
  &amp;&amp;&amp;&amp;&amp; \vdots \\
  &amp;&amp;&amp;&amp;&amp; 3g(10, [1, 1]) + 2y^2(10) \leq 2.
\end{aligned}\]</p><p>Now that the variables and constraints are are transcribed, all that remains is  to add relations to define the behavior of the transcribed partial derivatives.  We can accomplish this via backward finite difference which will just add one  infinite equation in this case this we only have 2 supports in the time domain  is then transcribed over the spatial domain to yield:</p><p class="math-container">\[\begin{aligned}
&amp;&amp;&amp; g(10, [-1, -1]) = g(0, [-1, -1]) + 10\frac{\partial g(10, [-1, -1])}{\partial t} \\
&amp;&amp;&amp; g(10, [-1, 1]) = g(0, [-1, 1]) + 10\frac{\partial g(10, [-1, 1])}{\partial t} \\
&amp;&amp;&amp; g(10, [1, -1]) = g(0, [1, -1]) + 10\frac{\partial g(10, [1, -1])}{\partial t} \\
&amp;&amp;&amp; g(10, [1, 1]) = g(0, [1, 1]) + 10\frac{\partial g(10, [1, 1])}{\partial t}
\end{aligned}\]</p><p>Now the problem is fully transcribed (discretized) and can be solved as a  standard optimization problem. Note that with realistic measure evaluation  schemes more supports might be added to the support sets and these will need to  be incorporated when transcribing variables and constraints.</p><p>It is easy to imagine how the above procedure can get quite involved to do manually,  but this is precisely what <code>InfiniteOpt</code> automates behind the scenes. Let&#39;s  highlight this by repeating the same example using <code>InfiniteOpt</code> (again using  the incorrect simple representation for the integrals for conciseness).</p><pre><code class="language-julia">using InfiniteOpt

# Initialize model
inf_model = InfiniteModel()

# Define parameters and supports
@infinite_parameter(inf_model, t in [0, 10], supports = [0, 10])
@infinite_parameter(inf_model, x[1:2] in [-1, 1], supports = [-1, 1], independent = true)

# Define variables
@variable(inf_model, y, Infinite(t))
@variable(inf_model, g, Infinite(t, x))

# Set the objective (using support_sum for the integral given our simple example)
# Note: In real problems integral should be used
@objective(inf_model, Min, support_sum(y^2, t))

# Define the constraints
@constraint(inf_model, y(0) == 1)
@constraint(inf_model, g(0, x) == 0)
@constraint(inf_model, support_sum(deriv(g, t), x) == 42) # support_sum for simplicity
@constraint(inf_model, 3g + y^2 &lt;= 2)

# Print the infinite model
print(inf_model)

# output
Min support_sum{t}[y(t)²]
Subject to
 y(0) = 1.0
 g(0, [x[1], x[2]]) = 0.0, ∀ x[1] ∈ [-1, 1], x[2] ∈ [-1, 1]
 support_sum{x}[∂/∂t[g(t, x)]] = 42.0, ∀ t ∈ [0, 10]
 y(t)² + 3 g(t, x) ≤ 2.0, ∀ t ∈ [0, 10], x[1] ∈ [-1, 1], x[2] ∈ [-1, 1]</code></pre><p>Thus, we obtain the infinite problem in <code>InfiniteOpt</code>. As previously noted,  transcription would be handled automatically behind the scenes when the model is  optimized. However, we can directly extract the transcribed version by building a  <code>TranscriptionModel</code>:</p><pre><code class="language-julia-repl">julia&gt; build_optimizer_model!(inf_model)

julia&gt; trans_model = optimizer_model(inf_model);

julia&gt; print(trans_model)
Min y(support: 1)² + y(support: 2)²
Subject to
 y(support: 1) = 1.0
 g(support: 1) = 0.0
 g(support: 3) = 0.0
 g(support: 5) = 0.0
 g(support: 7) = 0.0
 ∂/∂t[g(t, x)](support: 1) + ∂/∂t[g(t, x)](support: 3) + ∂/∂t[g(t, x)](support: 5) + ∂/∂t[g(t, x)](support: 7) = 42.0
 ∂/∂t[g(t, x)](support: 2) + ∂/∂t[g(t, x)](support: 4) + ∂/∂t[g(t, x)](support: 6) + ∂/∂t[g(t, x)](support: 8) = 42.0
 g(support: 1) - g(support: 2) + 10 ∂/∂t[g(t, x)](support: 2) = 0.0
 g(support: 3) - g(support: 4) + 10 ∂/∂t[g(t, x)](support: 4) = 0.0
 g(support: 5) - g(support: 6) + 10 ∂/∂t[g(t, x)](support: 6) = 0.0
 g(support: 7) - g(support: 8) + 10 ∂/∂t[g(t, x)](support: 8) = 0.0
 y(support: 1)² + 3 g(support: 1) ≤ 2.0
 y(support: 2)² + 3 g(support: 2) ≤ 2.0
 y(support: 1)² + 3 g(support: 3) ≤ 2.0
 y(support: 2)² + 3 g(support: 4) ≤ 2.0
 y(support: 1)² + 3 g(support: 5) ≤ 2.0
 y(support: 2)² + 3 g(support: 6) ≤ 2.0
 y(support: 1)² + 3 g(support: 7) ≤ 2.0
 y(support: 2)² + 3 g(support: 8) ≤ 2.0</code></pre><p>This precisely matches what we found analytically. Note that the unique support  combinations are determined automatically and are represented visually as  <code>support: #</code>. The precise support values can be looked up via <code>supports</code>:</p><pre><code class="language-julia-repl">julia&gt; supports(y)
2-element Vector{Tuple}:
 (0.0,)
 (10.0,)

julia&gt; supports(g)
8-element Vector{Tuple}:
 (0.0, [-1.0, -1.0])
 (10.0, [-1.0, -1.0])
 (0.0, [1.0, -1.0])
 (10.0, [1.0, -1.0])
 (0.0, [-1.0, 1.0])
 (10.0, [-1.0, 1.0])
 (0.0, [1.0, 1.0])
 (10.0, [1.0, 1.0])

julia&gt; supports(g, ndarray = true) # format it as an n-dimensional array (t by x[1] by x[2])
2×2×2 Array{Tuple, 3}:
[:, :, 1] =
 (0.0, [-1.0, -1.0])   (0.0, [1.0, -1.0])
 (10.0, [-1.0, -1.0])  (10.0, [1.0, -1.0])

[:, :, 2] =
 (0.0, [-1.0, 1.0])   (0.0, [1.0, 1.0])
 (10.0, [-1.0, 1.0])  (10.0, [1.0, 1.0])</code></pre><h2 id="TranscriptionOpt"><a class="docs-heading-anchor" href="#TranscriptionOpt">TranscriptionOpt</a><a id="TranscriptionOpt-1"></a><a class="docs-heading-anchor-permalink" href="#TranscriptionOpt" title="Permalink"></a></h2><p><code>InfiniteOpt.TranscriptionOpt</code> is a sub-module which principally implements  <code>TranscriptionModel</code>s and its related access/modification methods. Thus,  this section will detail what these are and how they work.</p><h3 id="TranscriptionModels"><a class="docs-heading-anchor" href="#TranscriptionModels">TranscriptionModels</a><a id="TranscriptionModels-1"></a><a class="docs-heading-anchor-permalink" href="#TranscriptionModels" title="Permalink"></a></h3><p>A <code>TranscriptionModel</code> is simply a <code>JuMP.Model</code> whose <code>ext</code> field contains  <a href="../../manual/transcribe/#InfiniteOpt.TranscriptionOpt.TranscriptionData"><code>TranscriptionData</code></a> which acts to map the transcribed model back to the  original infinite model (e.g., map the variables and constraints). Such models  are constructed via a default version of  <a href="../../manual/transcribe/#InfiniteOpt.build_optimizer_model!-Tuple{InfiniteModel, Val{:TransData}}"><code>build_optimizer_model!</code></a>  which wraps <a href="../../manual/transcribe/#InfiniteOpt.TranscriptionOpt.build_transcription_model!"><code>build_transcription_model!</code></a>:</p><pre><code class="language-julia-repl">julia&gt; model1 = TranscriptionModel() # make an empty model
A JuMP Model
Feasibility problem with:
Variables: 0
Model mode: AUTOMATIC
CachingOptimizer state: NO_OPTIMIZER
Solver name: No optimizer attached.

julia&gt; build_optimizer_model!(inf_model); 

julia&gt; model2 = optimizer_model(inf_model) # generate from an InfiniteModel
A JuMP Model
Minimization problem with:
Variables: 4
Objective function type: AffExpr
`AffExpr`-in-`MathOptInterface.EqualTo{Float64}`: 1 constraint
`QuadExpr`-in-`MathOptInterface.LessThan{Float64}`: 3 constraints
`VariableRef`-in-`MathOptInterface.GreaterThan{Float64}`: 3 constraints
`VariableRef`-in-`MathOptInterface.ZeroOne`: 1 constraint
Model mode: AUTOMATIC
CachingOptimizer state: NO_OPTIMIZER
Solver name: No optimizer attached.</code></pre><p>Note that the all the normal <code>JuMP.Model</code> arguments can be used with both  constructor when making an empty model and they are simply inherited from those   specified in the <code>InfiniteModel</code>. The call to <code>build_optimizer_model!</code> is the backbone  behind infinite model transcription and is what encapsulates all of the methods to  transcribe measures, variables, derivatives, and constraints. This is also the  method that enables the use of <a href="../../manual/optimize/#JuMP.optimize!-Tuple{InfiniteModel}"><code>optimize!</code></a>.</p><h3 id="Queries"><a class="docs-heading-anchor" href="#Queries">Queries</a><a id="Queries-1"></a><a class="docs-heading-anchor-permalink" href="#Queries" title="Permalink"></a></h3><p>In this section we highlight a number of query methods that pertain to  <code>TranscriptionModel</code>s and their mappings. First, if the <code>optimizer_model</code> of an  <code>InfiniteModel</code> is a <code>TranscriptionModel</code> it can be extracted via  <a href="../../manual/transcribe/#InfiniteOpt.TranscriptionOpt.transcription_model"><code>transcription_model</code></a>:</p><pre><code class="language-julia-repl">julia&gt; transcription_model(inf_model)
A JuMP Model
Feasibility problem with:
Variables: 0
Model mode: AUTOMATIC
CachingOptimizer state: NO_OPTIMIZER
Solver name: No optimizer attached.</code></pre><p>Here we observe that such a model is currently empty and hasn&#39;t been populated  yet. Furthermore, we check that a <code>Model</code> is an <code>TranscriptionModel</code> via  <a href="../../manual/transcribe/#InfiniteOpt.TranscriptionOpt.is_transcription_model"><code>is_transcription_model</code></a>: </p><pre><code class="language-julia-repl">julia&gt; is_transcription_model(optimizer_model(inf_model))
true

julia&gt; is_transcription_model(Model())
false</code></pre><p>We can also extract the raw <a href="../../manual/transcribe/#InfiniteOpt.TranscriptionOpt.TranscriptionData"><code>TranscriptionData</code></a> object from a  <code>TranscriptionModel</code> via <a href="../../manual/transcribe/#InfiniteOpt.TranscriptionOpt.transcription_data"><code>transcription_data</code></a>.</p><pre><code class="language-julia-repl">julia&gt; transcription_data(trans_model);</code></pre><p>Next we can retrieve the <code>JuMP</code> variable(s) for a particular <code>InfiniteOpt</code>  variable via <a href="../../manual/transcribe/#InfiniteOpt.TranscriptionOpt.transcription_variable-Tuple{Model, GeneralVariableRef}"><code>transcription_variable</code></a>. For finite variables, this will  be a one to one mapping, and for infinite variables a list of supported variables  will be returned in the order of the supports. Following the initial example in  the basic usage section, this is done:</p><pre><code class="language-julia-repl">julia&gt; build_optimizer_model!(inf_model); trans_model = optimizer_model(inf_model);

julia&gt; transcription_variable(trans_model, y)
3-element Vector{VariableRef}:
 y(support: 1)
 y(support: 2)
 y(support: 3)

julia&gt; transcription_variable(trans_model, z)
z</code></pre><p>Note that if the <code>TranscriptionModel</code> is stored as the current <code>optimizer_model</code>  then the first argument (specifying the <code>TranscriptionModel</code> can be omitted). Thus,   in this case the first argument can be omitted as it was above, but is shown for  completeness.</p><p>Similarly, the parameter supports corresponding to the transcription variables  (in the case of transcribed infinite variables) can be queried via  <a href="../../manual/expression/#InfiniteOpt.supports-Tuple{GeneralVariableRef}"><code>supports</code></a>:</p><pre><code class="language-julia-repl">julia&gt; supports(y)
3-element Vector{Tuple}:
 (0.0,)
 (5.0,)
 (10.0,)</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><ol><li>Note that like <code>supports</code> the <code>transcription_[obj]</code> methods also employ the  <code>label::Type{AbstractSupportLabel} = PublicLabel</code> keyword argument that by  default will return variables/expressions/constraints associated with public  supports. The full set (e.g., ones corresponding to internal collocation nodes)  is obtained via <code>label = All</code>. </li><li>These methods also employ the <code>ndarray::Bool</code> keyword argument that will cause the  output to be formatted as a n-dimensional array where the dimensions  correspond to the infinite parameter dependencies. For example, if we have an  infinite variable <code>y(t, ξ)</code> and we invoke a query method with <code>ndarray = true</code>  then we&#39;ll get a matrix whose dimensions correspond to the supports of <code>t</code> and  <code>ξ</code>, respectively. Also, if <code>ndarray = true</code> then <code>label</code> correspond to the  intersection of supports labels in contrast to its default of invoking the union  of the labels.</li></ol></div></div><p>Likewise, <a href="../../manual/transcribe/#InfiniteOpt.TranscriptionOpt.transcription_constraint-Tuple{Model, InfOptConstraintRef}"><code>transcription_constraint</code></a> and  <code>supports</code>(@ref) can be used with constraints to find their transcribed   equivalents in the <code>JuMP</code> model and determine their supports.</p><p>We can also do this with measures and expressions:</p><pre><code class="language-julia-repl">julia&gt; meas = support_sum(y^2, t)
support_sum{t}[y(t)²]

julia&gt; build_optimizer_model!(inf_model)

julia&gt; transcription_variable(meas)
y(support: 1)² + y(support: 2)² + y(support: 3)²

julia&gt; supports(meas)
()

julia&gt; transcription_expression(y^2 + z - 42)
3-element Vector{AbstractJuMPScalar}:
 y(support: 1)² + z - 42
 y(support: 2)² + z - 42
 y(support: 3)² + z - 42

julia&gt; supports(y^2 + z - 42)
3-element Vector{Tuple}:
 (0.0,)
 (5.0,)
 (10.0,)

julia&gt; parameter_refs(y^2 + z - 42)
(t,)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../constraint/">« Constraints</a><a class="docs-footer-nextpage" href="../optimize/">Optimization »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 23 June 2021 21:04">Wednesday 23 June 2021</span>. Using Julia version 1.6.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
